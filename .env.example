# =============================================================================
# Unified RAG Configuration
# =============================================================================
# This file configures all three capabilities:
#   1. Gosu code ingestion (from gosu-chroma-rag)
#   2. PDF documentation ingestion (from chroma-rag-docs)
#   3. RAG agent for querying

# -----------------------------------------------------------------------------
# LLM Provider Configuration
# -----------------------------------------------------------------------------
# Provider: 'openai' | 'anthropic' | 'azure_openai' | 'google'
PROVIDER=google

# Model identifier (e.g., 'gpt-4o-mini', 'gemini-2.5-flash', 'claude-3-5-sonnet-20241022')
MODEL=gemini-2.5-flash

# Tool schema format: 'openai' | 'anthropic'
TOOL_FORMAT=openai

# -----------------------------------------------------------------------------
# OpenAI Configuration
# -----------------------------------------------------------------------------
OPENAI_API_KEY=your-openai-api-key-here

# -----------------------------------------------------------------------------
# Anthropic Configuration
# -----------------------------------------------------------------------------
# ANTHROPIC_API_KEY=your-anthropic-api-key-here

# -----------------------------------------------------------------------------
# Azure OpenAI Configuration
# -----------------------------------------------------------------------------
# AZURE_OPENAI_API_KEY=your-azure-openai-api-key-here
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_DEPLOYMENT=your-deployment-name

# -----------------------------------------------------------------------------
# Google Gemini Configuration
# -----------------------------------------------------------------------------
# GOOGLE_API_KEY=your-google-api-key-here

# -----------------------------------------------------------------------------
# Embedding Configuration
# -----------------------------------------------------------------------------
# Embedding provider: 'openai' | 'google' | 'ollama' (recommended)
EMBEDDING_PROVIDER=ollama

# Embedding model
# OpenAI: text-embedding-ada-002, text-embedding-3-small
# Google: text-embedding-004
# Ollama: mxbai-embed-large (recommended), nomic-embed-text, all-minilm
EMBEDDING_MODEL=mxbai-embed-large

# Optional: Override API key for embeddings (defaults to provider's main API key)
# EMBEDDING_API_KEY=

# -----------------------------------------------------------------------------
# Ollama Configuration (for EMBEDDING_PROVIDER=ollama)
# -----------------------------------------------------------------------------
# Local Ollama embedding is 50-100x faster than API-based providers
# Install: brew install ollama && ollama pull mxbai-embed-large
OLLAMA_HOST=http://localhost:11434

# -----------------------------------------------------------------------------
# Guidewire Source Configuration (Multi-Module)
# -----------------------------------------------------------------------------
# JSON array of source locations. Each entry represents a Guidewire module with:
#   - module: Identifier (policycenter, billingcenter, contactmanager)
#   - codePath: Path to Gosu source code
#   - docsPath: Path to PDF documentation (optional)
#
# Example with all three modules:
GUIDEWIRE_SOURCES='[
  {"module":"policycenter","codePath":"/path/to/PolicyCenter","docsPath":"/path/to/docs/PolicyCenter"},
  {"module":"billingcenter","codePath":"/path/to/BillingCenter","docsPath":"/path/to/docs/BillingCenter"},
  {"module":"contactmanager","codePath":"/path/to/ContactManager","docsPath":"/path/to/docs/ContactManager"}
]'

# -----------------------------------------------------------------------------
# Vector Store Configuration
# -----------------------------------------------------------------------------
# Vector store type (currently only 'chroma' is supported)
VECTOR_STORE=chroma

# Chroma server configuration
CHROMA_HOST=localhost
CHROMA_PORT=8000

# Collection names for ingestion and query
CODE_COLLECTION=guidewire-code
DOCS_COLLECTION=docs

# Collections to query (comma-separated, used by RAG agent)
CHROMA_COLLECTIONS=guidewire-code,docs

# Optional: Chroma tenant and database (for multi-tenant deployments)
# CHROMA_TENANT=default_tenant
# CHROMA_DATABASE=default_database

# -----------------------------------------------------------------------------
# Ingestion Configuration
# -----------------------------------------------------------------------------
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Semantic Units (Gosu) - Comma separated
GOSU_SEMANTIC_UNITS=uses_statement,class_declaration,interface_declaration,enum_declaration,enhancement_declaration,function_declaration,property_declaration

# Semantic Units (Gosu Templates) - Comma separated
GOSU_TEMPLATE_SEMANTIC_UNITS=directive,scriptlet,expression,declaration
 
# Embedding Performance (optimized for Ollama local embeddings)
# Reduce these values if using API-based providers to avoid rate limits
EMBEDDING_BATCH_SIZE=500
EMBEDDING_CONCURRENCY=10

# -----------------------------------------------------------------------------
# Agent Runtime Configuration
# -----------------------------------------------------------------------------
# Maximum number of tool calls per step
MAX_TURNS=30

# Default number of results from semantic search
TOP_K=10

# Logging level: 'error' | 'warn' | 'info' | 'debug' | 'trace'
LOG_LEVEL=info

# -----------------------------------------------------------------------------
# Agent System Prompt
# -----------------------------------------------------------------------------
# Path to the agent system prompt markdown file
# Can be absolute or relative to project root
AGENT_SYSTEM_PROMPT_PATH=prompts/agent_system.md

# Alternative prompt files for different environments:
# AGENT_SYSTEM_PROMPT_PATH=./prompts/production-agent.md
# AGENT_SYSTEM_PROMPT_PATH=./prompts/dev-agent.md

# -----------------------------------------------------------------------------
# Optional: Prompt Overrides
# -----------------------------------------------------------------------------
# You can override individual prompts by specifying them here.
# Leave commented to use defaults from src/config/prompts.ts

# PROMPT_PLANNER_SYSTEM_PATH="prompts/planner_system.md"
# PROMPT_STEP_SYSTEM_PATH="prompts/step_system.md"
# PROMPT_STEP_DEVELOPER_PATH="prompts/step_developer.md"
# PROMPT_EVALUATOR_SYSTEM_PATH="prompts/evaluator_system.md"
# PROMPT_FINALIZER_SYSTEM_PATH="prompts/finalizer_system.md"

# -----------------------------------------------------------------------------
# Memory Configuration
# -----------------------------------------------------------------------------
# Enable or disable conversation memory (set to 'false' to disable)
MEMORY_ENABLED=true

# Number of turns to include in the context
HISTORY_CONTEXT_SIZE=6

# Total number of turns to keep in history
HISTORY_RETENTION_SIZE=50

# -----------------------------------------------------------------------------
# Memory - Advanced (Summarization & Duplicate Detection)
# -----------------------------------------------------------------------------
# Enable automatic summarization of older history to stay within token limits
MEMORY_SUMMARIZATION_ENABLED=true

# Maximum tokens for history context (triggers summarization when exceeded)
MEMORY_MAX_TOKENS=2000

# Similarity threshold for duplicate query detection (0.0-1.0)
# Uses embedding similarity to detect repeated questions
MEMORY_CACHE_THRESHOLD=0.85

# =============================================================================
# End of Configuration
# =============================================================================
